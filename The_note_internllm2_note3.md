# 书生·浦语大模型学习第二节学习笔记
## 学习内容概述
### 学习笔记
1. 介绍了RAG的基本知识内容
2. RAG目前的三个类别
![image](https://github.com/PURE281/my_dream/assets/93171238/25a91afe-bd5b-42c1-836d-dd2f0a8fa7e4)
3. RAG常见的优化方法
嵌入优化-结合稀疏和密集检索 多任务
索引优化-细粒度分割（Chunk） 元数据
查询优化-查询扩展、转换 多查询
上下文管理-重排（rerank） 上下文选择/压缩
迭代检索-根据初始查询和迄今为止生成的文本进行重复搜索
递归检索-迭代细化搜索查询 链式推理（Chain-of-Thought）指导检索过程
自适应检索-Flare，Self=RAG 使用LLMs主动决定检索的最佳时机和内容
LLM微调-检索微调 生成微调 双重微调
![image](https://github.com/PURE281/my_dream/assets/93171238/fcd0a700-2f21-4cc9-8933-d872c2c8b4ae)

4. RAG和微调（Fine-tuning）的区别 
RAG
- 非参数记忆，利用外部知识库提供实时更新的信息
- 能够处理知识密集型任务，提供准确的事实性回答
- 通过检索增强，可以生成更多样化的内容
适用场景
- 适用于需要结合最新信息和实时数据的任务；开放域问答、实时新闻摘要等

优势
- 动态知识更新，处理长尾知识问题

局限
- 依赖于外部知识库的质量和覆盖范围。依赖大模型能力

微调 Fine-tuning
- 参数记忆，通过在特定任务数据上的训练，模型可以更好地适应该任务
- 通常需要大量标注数据来进行有效微调
- 微调后的模型可能过拟合，导致泛化能力下降

适用场景
- 适用于数据可用且需要模型高度专业化的任务，如特定领域的文本分类， 情感分享、文本生成等

优势
- 模型性能针对特定任务优化

局限
- 需要大量的标注数据，且对新任务的适应性较差

![image](https://github.com/PURE281/my_dream/assets/93171238/560e6027-e90b-443f-83b4-52f353ff2bf8)
